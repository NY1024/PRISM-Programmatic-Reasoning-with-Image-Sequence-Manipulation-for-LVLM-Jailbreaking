# PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking

This repository contains the **official code implementation** of the paper:
**PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking**.

---

## ðŸ“– Introduction

PRISM introduces a novel programmatic reasoning framework for constructing adversarial image sequences to jailbreak Large Vision-Language Models (LVLMs). By leveraging image sequence manipulation, PRISM achieves strong jailbreak performance with simple yet effective designs.

This repository provides the **initial release** of code, including:

* Basic **data processing scripts**
* **Ablation study code**
* **Plotting utilities**
* **Proof-of-concept (PoC) main experiment code**

The core file is `poc.py`, which implements the most **naÃ¯ve version** of PRISM. Despite its simplicity, this version already achieves **high jailbreak success rates**.

---

## ðŸ“‚ Repository Structure

```
.
â”œâ”€â”€ data/              # Data preprocessing scripts
â”œâ”€â”€ ablation/          # Partial ablation experiment code
â”œâ”€â”€ plots/             # Visualization and plotting scripts
â”œâ”€â”€ main/           # Core proof-of-concept implementation
â””â”€â”€ README.md
```

---

## ðŸš€ Updates

* Upon acceptance of the paper, we will **release the full codebase**, including implementations of our **current algorithms** and complete experimental pipelines.

---

## ðŸ“¦ Adversarial Image Dataset

To facilitate reproducibility and **out-of-the-box usage**, we provide adversarial images generated by PRISM using **FigStep** and **MMSafetyBench** text datasets on Hugging Face:

ðŸ‘‰ [Dataset Link](https://huggingface.co/datasets/Zonghao2025/PRISM_Adversarial_Image_Dataset)

---

## ðŸ“œ Citation

If you find this repository useful, please cite our work:

```bibtex
@article{zou2025prism,
  title={PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking},
  author={Zou, Quanchen and Ying, Zonghao and Chen, Moyang and Xu, Wenzhuo and Xiao, Yisong and Li, Yakai and Zhang, Deyue and Yang, Dongdong and Liu, Zhao and Zhang, Xiangzheng},
  journal={arXiv preprint arXiv:2507.21540},
  year={2025}
}
```

